{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments with b = -1:\n",
      "  Experiments with N = 500:\n",
      "    Experiment data: [92, 0.8008, 1385.2676928043365]\n",
      "    Experiment data: [101, 0.7886, 1852.1650879383087]\n",
      "    Experiment data: [89, 0.7918, 1408.7474071979523]\n",
      "    Experiment data: [91, 0.791, 1433.421273946762]\n",
      "    Experiment data: [93, 0.7992, 1686.6987035274506]\n",
      "    Experiment data: [83, 0.798, 1402.390331029892]\n",
      "    Experiment data: [87, 0.7864, 1300.8102056980133]\n",
      "    Experiment data: [91, 0.8116, 1536.713322877884]\n",
      "    Experiment data: [104, 0.793, 2168.0915188789368]\n",
      "    Experiment data: [108, 0.7922, 2332.5381438732147]\n",
      "Experiments with b = 0:\n",
      "  Experiments with N = 1:\n",
      "    Experiment data: [211, 0.785, 2879.9784038066864]\n",
      "    Experiment data: [210, 0.8027, 2932.3846418857574]\n",
      "    Experiment data: [221, 0.781, 3046.202001094818]\n",
      "    Experiment data: [185, 0.7883, 2283.041822910309]\n",
      "    Experiment data: [183, 0.8047, 2356.5532450675964]\n",
      "    Experiment data: [201, 0.7973, 2890.8788261413574]\n",
      "    Experiment data: [196, 0.7793, 2501.194744825363]\n",
      "    Experiment data: [175, 0.801, 2197.3756189346313]\n",
      "    Experiment data: [193, 0.7897, 2559.2548298835754]\n",
      "    Experiment data: [205, 0.7983, 2891.203600168228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-e88be01954b5>:58: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  np.sum(len(g) for g in data['rb']), coverage , data['ttotal']])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "logs_directory = 'logs'\n",
    "\n",
    "# Get a list of all subdirectories in the logs directory\n",
    "experiment_directories = [directory for directory in glob.glob(os.path.join(logs_directory, '*')) if os.path.isdir(directory)]\n",
    "\n",
    "# Define a dictionary to store the grouped experiments\n",
    "grouped_experiments = {}\n",
    "\n",
    "# Iterate over each experiment directory\n",
    "for experiment_directory in experiment_directories:\n",
    "    # Parse the experiment name\n",
    "    experiment_name = os.path.basename(experiment_directory)\n",
    "    name_parts = experiment_name.split('_')\n",
    "    \n",
    "    # Extract the relevant values from the experiment name\n",
    "    if 'naive' in name_parts:\n",
    "        b = 0 if 'naive' in name_parts else -1#int(name_parts[-5])\n",
    "    elif 'greedy' in name_parts and 'cvx' not in name_parts and int(name_parts[-4]) >=41:\n",
    "        b = -1\n",
    "    else:\n",
    "        continue\n",
    "    N = int(name_parts[-3])\n",
    "    \n",
    "    # Get the last pickle file in the 'data' subdirectory\n",
    "    data_directory = os.path.join(experiment_directory, 'data')\n",
    "    pickle_files = glob.glob(os.path.join(data_directory, '*.pkl'))\n",
    "    last_pickle_file = max(pickle_files, key=os.path.getctime)\n",
    "    \n",
    "    # Load the last pickle file\n",
    "    with open(last_pickle_file, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    \n",
    "    # Find the 'summar' subdirectory and get the path to the text file\n",
    "    summar_directory = os.path.join(experiment_directory, 'summary')\n",
    "    text_files = glob.glob(os.path.join(summar_directory, '*.txt'))\n",
    "    last_text_file = max(text_files, key=os.path.getctime)\n",
    "    \n",
    "    # Read the last line of the text file to extract coverage\n",
    "    with open(last_text_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        last_line = lines[-2].strip()\n",
    "        coverage = float(last_line.split()[1])\n",
    "\n",
    "    # Group experiments by 'b' value\n",
    "    if b not in grouped_experiments:\n",
    "        grouped_experiments[b] = {}\n",
    "    \n",
    "    # Group experiments by 'N' value\n",
    "    if N not in grouped_experiments[b]:\n",
    "        grouped_experiments[b][N] = []\n",
    "    \n",
    "    # Add the experiment data to the grouped experiments dictionary\n",
    "    grouped_experiments[b][N].append([\n",
    "            np.sum(len(g) for g in data['rb']), coverage , data['ttotal']])\n",
    "\n",
    "# Print the grouped experiments\n",
    "for b, experiments in grouped_experiments.items():\n",
    "    print(f\"Experiments with b = {b}:\")\n",
    "    for N, experiment_data in experiments.items():\n",
    "        print(f\"  Experiments with N = {N}:\")\n",
    "        for datas in experiment_data:\n",
    "            print(f\"    Experiment data: {datas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regs 93.9 t 1650.7\n",
      "regs 7.5 t 338.8\n"
     ]
    }
   ],
   "source": [
    "data = np.array(grouped_experiments[-1][500])\n",
    "mean = data.mean(axis=0)\n",
    "std = data.std(axis=0)\n",
    "print(f\"regs {mean[0]:.1f} t {mean[2]:.1f}\")\n",
    "print(f\"regs {std[0]:.1f} t {std[2]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
